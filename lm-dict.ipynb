{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018bd896",
   "metadata": {},
   "source": [
    "# Loughran-McDonald Dictionary for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2bf1b",
   "metadata": {},
   "source": [
    "Data reference: [Notre Dame](https://sraf.nd.edu/loughranmcdonald-master-dictionary/)\n",
    "\n",
    "Processing reference: [Wharton](https://wrds-www.wharton.upenn.edu/pages/classroom/sec-filings-dictionary-based-sentiment-analysis/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f7685",
   "metadata": {},
   "source": [
    "## Load in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe9d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c9eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utf8len(s):\n",
    "    \"\"\"helper function to get the size of string\"\"\"\n",
    "    return len(s.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ceb0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your master dictionary file. This file requires a\n",
    "# Word column and a Syllables column. Other columns are optional\n",
    "# and should be defined in the SENTIMENT_OUTPUT_FIELDS Python dictionary below.\n",
    "master_dictionary_file = \"Loughran-McDonald_MasterDictionary_1993-2024.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888d0cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master dictionary has 86553 words.\n"
     ]
    }
   ],
   "source": [
    "# Load the master dictionary CSV file into a Python dictionary\n",
    "# with Word as the key.\n",
    "master_dictionary = {}\n",
    "with open(master_dictionary_file) as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=\",\")\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        master_dictionary[row[\"Word\"].lower()] = row\n",
    "        line_count += 1\n",
    "print(f\"master dictionary has {len(master_dictionary)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4799bf5",
   "metadata": {},
   "source": [
    "The dictionary is now loaded into memory. Let's inspect what information it contains for an example word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f02994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Word': 'KEY',\n",
       " 'Seq_num': '40955',\n",
       " 'Word Count': '4987086',\n",
       " 'Word Proportion': '0.00019519456055297713',\n",
       " 'Average Proportion': '0.00029559214410589807',\n",
       " 'Std Dev': '0.0012756908126321722',\n",
       " 'Doc Count': '1100659',\n",
       " 'Negative': '0',\n",
       " 'Positive': '0',\n",
       " 'Uncertainty': '0',\n",
       " 'Litigious': '0',\n",
       " 'Strong_Modal': '0',\n",
       " 'Weak_Modal': '0',\n",
       " 'Constraining': '0',\n",
       " 'Complexity': '0',\n",
       " 'Syllables': '1',\n",
       " 'Source': '12of12inf'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dictionary[\"key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a5def",
   "metadata": {},
   "source": [
    "Normalize words by lowercasing them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fdf6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master dictionary has 86553 words.\n"
     ]
    }
   ],
   "source": [
    "for key, item in master_dictionary.items():\n",
    "    item = {item_key.lower(): item_v for item_key, item_v in item.items()}\n",
    "    item['word'] = item['word'].lower()\n",
    "    master_dictionary[key] = item\n",
    "    \n",
    "    \n",
    "print(f\"master dictionary has {len(master_dictionary)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67bcb0",
   "metadata": {},
   "source": [
    "Convert numeric fields to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fcbc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in master_dictionary.items():\n",
    "    for field, value in item.items():\n",
    "        if type(value) == str and value.isdigit():\n",
    "            item[field] = int(value)\n",
    "        elif type(value) == str:\n",
    "            try:\n",
    "                item[field] = float(value)\n",
    "            except:\n",
    "                pass\n",
    "    master_dictionary[key] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e89b593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'key',\n",
       " 'seq_num': 40955,\n",
       " 'word count': 4987086,\n",
       " 'word proportion': 0.00019519456055297713,\n",
       " 'average proportion': 0.00029559214410589807,\n",
       " 'std dev': 0.0012756908126321722,\n",
       " 'doc count': 1100659,\n",
       " 'negative': 0,\n",
       " 'positive': 0,\n",
       " 'uncertainty': 0,\n",
       " 'litigious': 0,\n",
       " 'strong_modal': 0,\n",
       " 'weak_modal': 0,\n",
       " 'constraining': 0,\n",
       " 'complexity': 0,\n",
       " 'syllables': 1,\n",
       " 'source': '12of12inf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dictionary[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f057dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(master_dictionary['key']['word proportion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202701a",
   "metadata": {},
   "source": [
    "Sentiment scores are given *BY YEAR* added, but actual values are *categorical*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066f76c",
   "metadata": {},
   "source": [
    "## Calculate score of document based on sentiment\n",
    "\n",
    "- Assumes input of list of words/tokens\n",
    "- Assumes we are looking for negative, positive, and uncertainty\n",
    "- The following sentiments will be excluded: litigious, strong_modal, weak_modal, and constraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314a72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SENTIMENT_OUTPUT_FIELDS list below contains the sentiment fields we want\n",
    "# to include.\n",
    "SENTIMENT_OUTPUT_FIELDS = [\n",
    "    \"negative\",\n",
    "    \"positive\",\n",
    "    \"uncertainty\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a34689ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes doc has been cleaned and lowercased\n",
    "def calculate_sentiment_score(doc: list[str]):\n",
    "    token_count = 0\n",
    "    sentiment_counts = {k: 0 for k in SENTIMENT_OUTPUT_FIELDS}\n",
    "    for token in doc:\n",
    "        if token in master_dictionary:\n",
    "            token_count += 1\n",
    "            for sentiment in SENTIMENT_OUTPUT_FIELDS:\n",
    "                sentiment_counts[sentiment] += int(master_dictionary[token][sentiment] != 0)\n",
    "    return {k: v / token_count for k, v in sentiment_counts.items()}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f25c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = \"terrible horrible very bad day\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c76666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'terrible', 'seq_num': 76799, 'word count': 2963, 'word proportion': 1.1597182862266085e-07, 'average proportion': 1.0795392194729806e-07, 'std dev': 1.6821892318184515e-05, 'doc count': 276, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 3, 'source': '12of12inf'}\n",
      "{'word': 'horrible', 'seq_num': 35552, 'word count': 151, 'word proportion': 5.910140439426861e-09, 'average proportion': 9.87359857861409e-09, 'std dev': 1.502871043089561e-06, 'doc count': 102, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 3, 'source': '12of12inf'}\n",
      "{'word': 'very', 'seq_num': 83165, 'word count': 774789, 'word proportion': 3.0325243714722504e-05, 'average proportion': 3.322288557482321e-05, 'std dev': 9.990595973362199e-05, 'doc count': 363334, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 2, 'source': '12of12inf'}\n",
      "{'word': 'bad', 'seq_num': 5021, 'word count': 918952, 'word proportion': 3.596778395425293e-05, 'average proportion': 3.9945856379691524e-05, 'std dev': 0.00013316140192530163, 'doc count': 323220, 'negative': 2009, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 1, 'source': '12of12inf'}\n",
      "{'word': 'day', 'seq_num': 18322, 'word count': 11249938, 'word proportion': 0.0004403226060585758, 'average proportion': 0.0002749470166932892, 'std dev': 0.00044285367365621214, 'doc count': 769820, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 1, 'source': '12of12inf'}\n"
     ]
    }
   ],
   "source": [
    "for token in test_doc:\n",
    "    print(master_dictionary[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad00900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0.2, 'positive': 0.0, 'uncertainty': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_sentiment_score(test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd703b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc2 = \"happy sunny awesome ice cream sundae cool\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e0e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'happy', 'seq_num': 33779, 'word count': 9917, 'word proportion': 3.8815140885957736e-07, 'average proportion': 3.8237742179555884e-07, 'std dev': 1.434768683064166e-05, 'doc count': 5111, 'negative': 0, 'positive': 2009, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 2, 'source': '12of12inf'}\n",
      "{'word': 'sunny', 'seq_num': 74714, 'word count': 6486, 'word proportion': 2.5386205887498427e-07, 'average proportion': 2.7938888778724973e-07, 'std dev': 1.3410517873374067e-05, 'doc count': 2387, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 2, 'source': '12of12inf'}\n",
      "{'word': 'awesome', 'seq_num': 4726, 'word count': 723, 'word proportion': 2.8298222104010733e-08, 'average proportion': 2.742281749408698e-08, 'std dev': 3.951523000354606e-06, 'doc count': 339, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 2, 'source': '12of12inf'}\n",
      "{'word': 'ice', 'seq_num': 36421, 'word count': 203919, 'word proportion': 7.981390253427061e-06, 'average proportion': 6.455921979400453e-06, 'std dev': 0.00011717785630511032, 'doc count': 44586, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 1, 'source': '12of12inf'}\n",
      "{'word': 'cream', 'seq_num': 16903, 'word count': 53815, 'word proportion': 2.1063192566076594e-06, 'average proportion': 2.260707449427686e-06, 'std dev': 5.2141925181071275e-05, 'doc count': 11921, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 1, 'source': '12of12inf'}\n",
      "{'word': 'sundae', 'seq_num': 74680, 'word count': 268, 'word proportion': 1.0489520779909926e-08, 'average proportion': 9.728986651239352e-09, 'std dev': 1.3709697974964449e-06, 'doc count': 148, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 2, 'source': '12of12inf'}\n",
      "{'word': 'cool', 'seq_num': 15857, 'word count': 27543, 'word proportion': 1.0780331001532055e-06, 'average proportion': 1.1504380834041827e-06, 'std dev': 3.351564807420167e-05, 'doc count': 13138, 'negative': 0, 'positive': 0, 'uncertainty': 0, 'litigious': 0, 'strong_modal': 0, 'weak_modal': 0, 'constraining': 0, 'complexity': 0, 'syllables': 1, 'source': '12of12inf'}\n"
     ]
    }
   ],
   "source": [
    "for token in test_doc2:\n",
    "    print(master_dictionary[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c445c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0.0, 'positive': 0.14285714285714285, 'uncertainty': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_sentiment_score(test_doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045fddc0",
   "metadata": {},
   "source": [
    "## Now use python module LMSentimentDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8868b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from lm_sentiment import LMSentimentDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec902333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = LMSentimentDict(master_dictionary_file, SENTIMENT_OUTPUT_FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4049e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'happy',\n",
       " 'seq_num': 33779,\n",
       " 'word count': 9917,\n",
       " 'word proportion': 3.8815140885957736e-07,\n",
       " 'average proportion': 3.8237742179555884e-07,\n",
       " 'std dev': 1.434768683064166e-05,\n",
       " 'doc count': 5111,\n",
       " 'negative': 0,\n",
       " 'positive': 2009,\n",
       " 'uncertainty': 0,\n",
       " 'litigious': 0,\n",
       " 'strong_modal': 0,\n",
       " 'weak_modal': 0,\n",
       " 'constraining': 0,\n",
       " 'complexity': 0,\n",
       " 'syllables': 2,\n",
       " 'source': '12of12inf'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict.master_dictionary['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a4a563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['terrible', 'horrible', 'very', 'bad', 'day'] ['happy', 'sunny', 'awesome', 'ice', 'cream', 'sundae', 'cool']\n"
     ]
    }
   ],
   "source": [
    "print(test_doc, test_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f56f133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0.2, 'positive': 0.0, 'uncertainty': 0.0}\n",
      "{'negative': 0.0, 'positive': 0.14285714285714285, 'uncertainty': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_dict.calculate_sentiment_score(test_doc))\n",
    "print(sentiment_dict.calculate_sentiment_score(test_doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49609555",
   "metadata": {},
   "source": [
    "## Run on begie_book_1996_2025.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "979837cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe5bbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdf = pd.read_csv('beige_book_1996_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4227e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>10</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>moderate expansion of business activity charac...</td>\n",
       "      <td>1996-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>moderate economic growth continues to be repor...</td>\n",
       "      <td>1996-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>most district reports characterized early autu...</td>\n",
       "      <td>1997-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>district economies generally continue to expan...</td>\n",
       "      <td>1997-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>district economies generally continued to expa...</td>\n",
       "      <td>1997-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month                                                url  \\\n",
       "0  1996     10  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "1  1996     12  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "2  1997      1  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "3  1997      3  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "4  1997      5  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "\n",
       "                                                text   timestamp  \n",
       "0  moderate expansion of business activity charac...  1996-10-01  \n",
       "1  moderate economic growth continues to be repor...  1996-12-01  \n",
       "2  most district reports characterized early autu...  1997-01-01  \n",
       "3  district economies generally continue to expan...  1997-03-01  \n",
       "4  district economies generally continued to expa...  1997-05-01  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b5920e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_scores = []\n",
    "positive_scores = []\n",
    "uncertainty_scores = []\n",
    "for t in bbdf['text']:\n",
    "    doc_split = t.split(' ')\n",
    "    score = sentiment_dict.calculate_sentiment_score(doc_split)\n",
    "    negative_scores.append(score['negative'])\n",
    "    positive_scores.append(score['positive'])\n",
    "    uncertainty_scores.append(score['uncertainty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec94d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdf['negative_score'] = negative_scores\n",
    "bbdf['positive_score'] = positive_scores\n",
    "bbdf['uncertainty_score'] = uncertainty_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e7be814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>uncertainty_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>10</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>moderate expansion of business activity charac...</td>\n",
       "      <td>1996-10-01</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>moderate economic growth continues to be repor...</td>\n",
       "      <td>1996-12-01</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>most district reports characterized early autu...</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>district economies generally continue to expan...</td>\n",
       "      <td>1997-03-01</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.020087</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.federalreserve.gov/fomc/beigebook/...</td>\n",
       "      <td>district economies generally continued to expa...</td>\n",
       "      <td>1997-05-01</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month                                                url  \\\n",
       "0  1996     10  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "1  1996     12  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "2  1997      1  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "3  1997      3  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "4  1997      5  https://www.federalreserve.gov/fomc/beigebook/...   \n",
       "\n",
       "                                                text   timestamp  \\\n",
       "0  moderate expansion of business activity charac...  1996-10-01   \n",
       "1  moderate economic growth continues to be repor...  1996-12-01   \n",
       "2  most district reports characterized early autu...  1997-01-01   \n",
       "3  district economies generally continue to expan...  1997-03-01   \n",
       "4  district economies generally continued to expa...  1997-05-01   \n",
       "\n",
       "   negative_score  positive_score  uncertainty_score  \n",
       "0        0.029883        0.029883           0.010204  \n",
       "1        0.014639        0.024703           0.007319  \n",
       "2        0.035156        0.026367           0.004883  \n",
       "3        0.023581        0.020087           0.006114  \n",
       "4        0.027429        0.028997           0.001567  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33aa5377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06366630076838639"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(bbdf['negative_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eee4904c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010775862068965518"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(bbdf['negative_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9e852ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03530751708428246\n",
      "0.0023391812865497076\n"
     ]
    }
   ],
   "source": [
    "print(max(bbdf['positive_score']))\n",
    "print(min(bbdf['positive_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b74db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019243530192435302\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(max(bbdf['uncertainty_score']))\n",
    "print(min(bbdf['uncertainty_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bf1227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdf.to_csv(\"beige_book_sentiment_scores_1996_2025.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
